\section{Introduction}



J. Pearl, "Causal inference in statistics: An overview,"  Statistics Surveys,  3:96--146, 2009.

J. Pearl, "Causal Diagrams for Empirical Research" Biometrika, 82(4), 669--710, December 1995.

J. Tian and J. Pearl, "Probabilities of causation: Bounds and identification"  In Annals of Mathematics and Artificial Intelligence, Vol. 28, 287--313, 2000. 

J. Pearl, "The logic of counterfactuals in causal inference (Discussion of `Causal inference without counterfactuals' by A.P. Dawid)," In Journal of American Statistical Association, Vol. 95, No. 450, 428--435, June 2000.


J.Y. Halpern and J. Pearl, "Causes and explanations: A structural-model approach
-- Part I:  Causes"  In British Journal of Philosophy of Science,  56:843-887, 2005.  

(R-266-Part2):  [pdf]
J.Y. Halpern and J. Pearl, "Causes and explanations: A structural-model approach
-- Part II: Explanations"    In British Journal of Philosophy of Science,  56:889-911, 2005.  




The hard open problems of machine learning are intrinsically related to causality\cite{Scholkopf2019}.  Three fundamental obstacles are standing in our way to strong AI, including robustnesss(or adaptability), explainability and lacking of understanding cause-effect connections.  Pearl  asserts that all these obstacles can be overcome using causal modeling tools, in particular, causal diagrams  and their associated logic\cite{Pearl2019seven}.  % a.k.a. structural causal models(SCMs).  
How can machines represent causal knowledge in a way that would enable them to access the necessary information swiftly, answer questions correctly, and do it with ease, as a human can? This question, which is referred as "mini-Turning test" for AI, has been claimed as Pearl's life work\cite{Pearl2018}. 


 

Pearl propose the framework of structural causal models(SCM) \cite{pearl2009causal, Pearl2009, halpern2005causesI, halpern2005causesII} which deploys three parts, including graphical models, structural equations, and counterfactual and interventional logic. Graphical models serve as a language for representing what we know about the world, counterfactuals help us to articulate what we want to know, while structural equations serve to tie the two together in a solid semantics. In the meanwhile, competitive causal notations and frameworks, such as Dawid's regime indicator framework and Rubin's potential outcome, are also used with prons and cons\cite{Marloes2018, MigualA.Hernan2019, Imbens2015}. These different approaches to formalizing causal inquiries which, despite subtle differences, all build on a probabilistic graphical representation of the problem at hand. 


 
Back to the very nature of modeling, a model is an idealized representation of reality that hightlights some aspects and ignores others. Wheeler claims all things physical are information-theoretic in origin \footnote{It from bit symbolizes the idea that every time of the physical world has at bottom...an immaterial source and explanation...that all things physical are information-theoretic in origin and that this is a participatory universe. ---- John A. Wheeler} and Bernhard highlights the information processing aspect of causal modeling in his work\cite{Scholkopf2019}. The main focus of current causal models are modeling the disentangled form of the joint distribution, while there are certain degree of ignoring the information processing aspect. Pearl's $do$-operator is one of the most important causal semantics or notations during the past three decades of the \emph{causal revolution}.  The haunting "confounding" problem has been demystified with $do$-calculus and many other achievements, but criticisms of this notation still exist, especially on the empirical interpretation when applied to non-manipulable variables such as race, obesity, or cholesterol level\cite{Pearl2019do}.



% Physically, Einstein's theory of relativity tells us that time, length, and quality can change in different coordinate systems, but the causal relationship of events remain. 
% This provides us an intuition of invariant causal mechanism and strong objection to "removing of causal mechanisms" or "a minimal change on mechanisms" which is exactly the meaning of Pearl's intervention. Moreover, intensive theoretical effects torward the development of SCM have been made in the recent years. One central topic is how to do causal inference beyond DAGs. Some of them focus on the theoretical aspects of cyclic SCM \cite{Bongers2016, Forre2019do, Forre2018discovery}, and some of them connect equilibrums to feedbacks/cycles \cite{Laurizen2002, Blom2018, Bongers2018}. However, many measure-theoretic and other complications arise in the presence of cycles,  and these difficulties may explain why in most of the SCM literature so far acyclicity has been assumed, even though many causal systems in nature involve feedbacks/cycles.

论文 \cite{correacalculus} 中把 do 推广到 regime indicator 然后发现依旧有 three rules.

The main idea of regime indicator is to consider the 'seeing' and 'doing' as two types of regimes, a natural one and a set of interventional ones \cite{dawid2015statistical}. This notation has advantange in representing soft interventions  which do not fix a variable at a value, but just 'nudge' it, adding a random error, or somehow shift its distribution \cite{eberhardt2007interventions} and dynamic intervention.  The property of stability \cite{dawid2010identifying} or invariance \cite{hausman1999independence} of conditional distributions across regimes is required to predict effects of interventions from observational data and thus making regime less popular. The proposing of this notation reveals some weakness of $do$ intervention in representing various interventions used in empirical applications. Robins' potential outcome is defined as the hypothetical value of a variable if we force an observed variable to a given value which is essentially based on $do$ intervention. An attractive feature of Robins' approach is that it largely avoids making counterfactual independence assumptions that are experimentally untestable and potential outcomes can be combined with graphs though may not be immediately obvious\cite{Richardson2011, richardson2013single, Marloes2018}.  Much of the  work in economics is closer in spirit to the potential outcome framework\cite{Imbens2019}. 

 

All these approaches to causality can be combined with graphs and focus on modeling the joint distribution associated with the graph. Each approach has some its own issues,  here we are not working on those issue within the original framework. In contrast,  we will interpret causality as information transfer to highlight the information-theoretic aspect of causal models  by proposing a new concept of info intervention to go beyond traditional causal notations. We then will see that some existing issues  can be circumvented or alleviated. 

  
In this article, we first will review the frameworks of causal models and discuss issues of graphical or structural causal models. Then we propose the info intervention as an causal notation other than Pearl’s do intervention semantic, which emphasis the information aspects of causal models, and then show how (or exhibit potentials) to solve (or alleviate) those issues. After that, we use the simplest case for causal modeling --- directed acyclic graphs to explain info intervention and associated three-level question with example. The next part of this article presents the causal calculus for info intervention using the $\info(\cdot)$ operator corresponding to Pearl's 3 rules, and gives examples of application. We conclude that $\info(\cdot)$-operator is a necessary and useful tool for causal inference and info intervention may unify interventionism causality and understanding causality as information transfer.


\section{Preliminaries}

 
The notation of causality has been much examined, discussed and debated in science and philosophy over many centuries. Among many proposed frameworks for causality, Pearl's causal diagrams have been widely used in the real world to study the causal inference for observational data. In this section, we mainly introduce some preliminaries on Pearl's causal diagrams, which build on the structural causal model (\SCM) to make graphical assumptions of the underlying data generating process. 




\begin{Def}[\SCM\cite{Pearl2009}\cite{Pearl2018}]
	\label{SCM-def}
	An \SCM\,by definition consists of: 
	\begin{enumerate}
		\setlength\itemsep{0em}
		\item A set of nodes $V^+=U \dot \cup V$, where elements of $V$ correspond to endogenous variables, elements of $U$ to exogenous (or Latent) variables, and 
		$U \dot \cup V$ is the disjoint union of sets $U$ and $V$.
		
		\item An endogenous/exogenous space $\Xcal_v$ for every $v \in V^+$, $\Xcal:=\prod_{v \in V^+}\Xcal_v$.
		
		\item A product probability measure $\Pr:=\Pr_U=\otimes_{u \in U} \Pr_u$ on the latent space $\prod_{u \in U} \Xcal_u$. 
		
		\item A directed graph structure $G^+=(V^+, E^+)$, with a system of structural equations  $f_V = (f_v)_{v \in V}$:
		\[f_v: \; \prod_{s \in  Pa^{G^+}(v)}\Xcal_s \to \Xcal_v,\]
		where $Ch^{G^+}(U) \subseteq V$, all functions $f_V$ are measurable, and $Ch(\cdot )$ and $Pa(\cdot)$ are graphical terminology of Children and Parents variables, respectively. 
	\end{enumerate}
	Conventionally, an \SCM\,can be summarized by the tuple $M=(G^+,\Xcal,\Pr, f)$. Note that $G^+$ is referred as the augmented functional graph, while the functional graph which includes only endogenous variables, is denoted as $G$. 
\end{Def}

Based on an \SCM\,, the key implementation of Pearl's causal diagrams is to capture interventions and counterfactuals by using an intervention operator called  $do(X=x)$, which  
simulates physical interventions by deleting certain functions from the model, replacing them with a constant $X=x$, while keeping the rest of the model unchanged.
Formally, this \emph{do} intervention operator is defined as follows: 

\begin{Def}[\emph{do} intervention]
	\label{def:p-intervention}
	Given an \SCM\,$M=(G^+,\Xcal,\Pr, f)$ and any $I \subseteq V$, the do intervention $do(X_I=x_I)$ (or, in short, $do(x_I)$) maps $M$ to the intervened model $M_{do(X_I = x_I)} = (G^+,\Xcal,\Pr, \tilde{f})$, where
	$$
	\begin{aligned}
	\tilde f_i(X_U,X_V) := \begin{cases}
	x_i, & i \in I, \\
	f_i(X_U,X_V), & i \in V \setminus I \,.
	\end{cases}
	\end{aligned}
	$$
\end{Def}


%Pearl's causal diagrams

Since there has theoretical and technical complications in dealing with the cyclic (\emph{do} intervened) \SCM\cite{Bongers2016}, most of efforts are made to study the acyclic (\emph{do} intervened) \SCM, which is equivalent to the causal directed acyclic graph (DAG) \cite{Marloes2018}. In causal DAG, the causal semantics could be well defined without any complications.


% \cite{Marloes2018} 

\begin{Def}[Causal DAG]
	Consider a DAG $G=(V, E)$ and a random vector $X = (X_1, ..., X_K)$ with distribution $p$. Then, $G$ is called a causal DAG for $X$ if $p$ satisfies the following:
	\begin{enumerate}[(i)]
		\setlength\itemsep{0em}
		\item $p$ factorizes, and thus is Markov, according to $G$, and
		\item for any $A \subset V$, $B = V/A$,  and any $\tilde{x}_A, x_B$ in the domains of $X_A, X_B$,
		\begin{equation}\label{eq:sigma:do}
p(x	| do(\tilde{x}_A)) = \prod_{k \in B} p(x_k|x_{Pa(k)})  \prod_{j \in A} \mathbb{I}(x_j = \tilde{x}_j).
		\end{equation}
	\end{enumerate}
\end{Def}

Note that for the equivalence of acyclic SCM and causal DAG, we are assuming there have the same exogenous variables. For a causal DAG $G$, we can define its \emph{do}-intervened DAG. 

\begin{Def}[\emph{do}-intervened DAG]
	Consider an causal DAG $G = (V, E)$ and a do intervention $do(\tilde{x}_A)$. The do-intervened DAG, denoted by $G^{do(\tilde{x}_A)}$, has the joint distribution $p(x| do(\tilde{x}_A))$ in (\ref{eq:sigma:do}) for the counterfactual random vector $X^{do(\tilde{x}_A)}$.
\end{Def}

Under the causal DAG,  
the major obstacle to draw causal inference from data known as "deconfounded" is demystified through a "backdoor" graphical criterion; if this backdoor criterion does not hold, a symbolic engine called "do-calculus" (i.e., Pearl's 3-rules of causal calculus)  is also handily available.





% Regime indicator 为什么提出来。
% There are other two notations for causal modeling. The key idea of \emph{regime indicator} is to consider 'seeing' and 'doing' as two types of regimes, a natural one and a set of interventional ones. $p(x; \sigma = s) = p(x; s)$. Here, regimes refer to external circumstances under which we expect some aspects of the joint distribution of X to differ.

Besides Pearl's causal diagrams, the causal diagrams based on potential (or counterfactual) outcomes also provide useful tools to do causal inference for 
observational data.
In this framework, the causal effect of action $A$ on an outcome $Y$ is captured by 
the potential outcome $Y^{\tilde{a}}$, which is the value of $Y$ that we would observe if $A$ is set (or forced) to $\tilde{a}$.  Essentially, the potential outcomes framework 
is based on perfect (or atomatic) interventions, and its practical implementation relies on the following exchangeability condition.

\begin{Def}[Exchangeability]
	Exchangeability means that the counterfactual outcome and the actual treatment (or action) are independent, or $Y^{\tilde{a}} \indep A$, for all $\tilde{a}$.
\end{Def}


 
% By the \textbf{common cause principle} that for two statistically dependent variables there will always be a third cause variable explains there dependence, we can assume the independence of exogenous variables. In other words, 
% \begin{Def}[Causal Sufficient]
% 	If all dependencies among variables are captured by the causal model, then we call it causally sufficient.
% \end{Def}

%We have reviewed the main causal notations currently used by researchers. Now it's time for us to present our new notations for causal models.

% Pros and cons are among the above causal notations, we now present our semantic of intervention under the information view of causal models.

